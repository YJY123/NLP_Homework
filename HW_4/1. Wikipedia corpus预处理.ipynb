{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 生成停用词库（chinese_stopwords.txt取自高老师的GitHub）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_set = set()\n",
    "with open(\"E:/NLP/datasource/chinese_stopwords.txt\",'r',encoding=\"utf-8\") as stopwords:\n",
    "    for stopword in stopwords:\n",
    "        stopword_set.add(stopword.strip(\"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 定义正则匹配规则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = re.compile(\"[-~!@#$%^&*()_+`=\\[\\]\\\\\\{\\}\\\"|;':,./<>?·！@#￥%……&*（）——+【】、；‘：“”，。、《》？「『」』\\s+]\")\n",
    "zifu = re.compile(\"[A-Za-z0-9]+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 文本预处理函数（这里要处理的文本已经是经过wikipedia extractor抽取和繁简字转换）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_text(read_file_path, save_file_path):\n",
    "    \n",
    "    count=0\n",
    "    \n",
    "    file = open(read_file_path,\"r\",encoding=\"utf-8\")\n",
    "    content_line = file.readline()\n",
    "    output = open(save_file_path,\"w+\",encoding=\"utf-8\")\n",
    "    \n",
    "    article_contents = \"\"\n",
    "    while content_line:\n",
    "        if '<doc id=' in content_line:\n",
    "            content_line = file.readline()\n",
    "            content_line = file.readline()\n",
    "            continue\n",
    "        if '</doc>' in content_line:\n",
    "#             article_contents.strip()\n",
    "#             print (article_contents.strip())\n",
    "            count += 1\n",
    "            if count%5000 == 0:\n",
    "                print (count)\n",
    "            output.write(article_contents.strip()+\"\\n\")\n",
    "            article_contents = \"\"\n",
    "            content_line = file.readline()\n",
    "            continue\n",
    "        content_line = content_line.strip(\"\\n\") \n",
    "        if len(content_line) > 0:\n",
    "            content_line = punctuation.sub('', content_line)\n",
    "            content_line = zifu.sub('', content_line)\n",
    "            words = jieba.cut(content_line)\n",
    "            for word in words:\n",
    "                if word not in stopword_set and word != ' ':\n",
    "                    word.strip()\n",
    "                    article_contents += word+\" \"\n",
    "        content_line = file.readline()\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "70000\n",
      "75000\n",
      "80000\n",
      "85000\n",
      "90000\n",
      "95000\n",
      "100000\n",
      "105000\n",
      "110000\n",
      "115000\n",
      "120000\n",
      "125000\n",
      "130000\n",
      "135000\n",
      "140000\n",
      "145000\n",
      "150000\n",
      "155000\n",
      "160000\n",
      "165000\n",
      "170000\n",
      "175000\n",
      "180000\n",
      "185000\n",
      "190000\n",
      "195000\n",
      "200000\n",
      "205000\n",
      "210000\n",
      "215000\n",
      "220000\n",
      "225000\n",
      "230000\n",
      "235000\n",
      "240000\n",
      "245000\n",
      "250000\n",
      "255000\n",
      "260000\n",
      "265000\n",
      "270000\n"
     ]
    }
   ],
   "source": [
    "pre_text('E:/NLP/datasource/jf_wiki_02', 'E:/NLP/datasource/fc_jf_wiki_02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "70000\n",
      "75000\n",
      "80000\n",
      "85000\n",
      "90000\n",
      "95000\n",
      "100000\n",
      "105000\n",
      "110000\n",
      "115000\n",
      "120000\n",
      "125000\n",
      "130000\n",
      "135000\n",
      "140000\n",
      "145000\n",
      "150000\n",
      "155000\n",
      "160000\n",
      "165000\n",
      "170000\n",
      "175000\n",
      "180000\n",
      "185000\n",
      "190000\n",
      "195000\n",
      "200000\n",
      "205000\n",
      "210000\n",
      "215000\n"
     ]
    }
   ],
   "source": [
    "pre_text('E:/NLP/datasource/jf_wiki_00', 'E:/NLP/datasource/fc_jf_wiki_00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "70000\n",
      "75000\n",
      "80000\n",
      "85000\n",
      "90000\n",
      "95000\n",
      "100000\n",
      "105000\n",
      "110000\n",
      "115000\n",
      "120000\n",
      "125000\n",
      "130000\n",
      "135000\n",
      "140000\n",
      "145000\n",
      "150000\n",
      "155000\n",
      "160000\n",
      "165000\n",
      "170000\n",
      "175000\n",
      "180000\n",
      "185000\n",
      "190000\n",
      "195000\n",
      "200000\n",
      "205000\n",
      "210000\n",
      "215000\n",
      "220000\n",
      "225000\n",
      "230000\n",
      "235000\n",
      "240000\n",
      "245000\n",
      "250000\n",
      "255000\n",
      "260000\n",
      "265000\n",
      "270000\n",
      "275000\n",
      "280000\n",
      "285000\n",
      "290000\n",
      "295000\n",
      "300000\n",
      "305000\n",
      "310000\n",
      "315000\n",
      "320000\n",
      "325000\n",
      "330000\n",
      "335000\n",
      "340000\n",
      "345000\n",
      "350000\n",
      "355000\n",
      "360000\n",
      "365000\n",
      "370000\n",
      "375000\n",
      "380000\n",
      "385000\n",
      "390000\n",
      "395000\n",
      "400000\n",
      "405000\n",
      "410000\n",
      "415000\n",
      "420000\n",
      "425000\n",
      "430000\n",
      "435000\n",
      "440000\n",
      "445000\n",
      "450000\n",
      "455000\n",
      "460000\n",
      "465000\n",
      "470000\n",
      "475000\n",
      "480000\n",
      "485000\n",
      "490000\n",
      "495000\n",
      "500000\n",
      "505000\n",
      "510000\n",
      "515000\n",
      "520000\n",
      "525000\n",
      "530000\n",
      "535000\n",
      "540000\n",
      "545000\n",
      "550000\n",
      "555000\n",
      "560000\n",
      "565000\n",
      "570000\n",
      "575000\n"
     ]
    }
   ],
   "source": [
    "pre_text('E:/NLP/datasource/jf_wiki_01', 'E:/NLP/datasource/fc_jf_wiki_01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 合并处理好的文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_corpus():\n",
    "    output = open(\"E:/NLP/datasource/wiki_corpus\",\"w\",encoding=\"utf-8\")\n",
    "    input_ = \"E:/NLP/datasource/fc_jf_wiki_0\"\n",
    "    for i in range(3):\n",
    "        file_path = input_ + str(i)\n",
    "        file = open(file_path,\"r\",encoding=\"utf-8\")\n",
    "        line = file.readline() \n",
    "        while line:\n",
    "            line = line.strip(\"\\n\")\n",
    "            if len(line) > 0: output.writelines(line+\"\\n\")\n",
    "            line = file.readline()\n",
    "        file.close()\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_corpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 查看合并后的文本格式是否正确"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = open(\"E:/NLP/datasource/wiki_corpus\",\"r\",encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'测绘学 研究 测定 推算 地面 几何 位置 地球 形状 地球 重力场 据此 测量 地球表面 自然 物体 人工 设施 几何 分布 编制 比例尺 地图 理论 技术 学科 测绘学 研究 对象 地球 形态 位置 重力 分布 地理 空间信息 测绘学 认为 地球科学 一个 分支 学科 近年来 测绘学 研究 对象 地球表面 扩大 地外 空间 地球 内部 构造 领域 测绘学 进步 倚赖 人类 地球 形状 认识 深化 地图 制图 技术 提高 测绘 仪器 创新 变革 世界 上古史 时代 利用 测绘学 治理 尼罗河 泛滥 农田 边界 说法 公元前 世纪 管仲 著 管子 一书 收集 早期 地图 幅 公元前 世纪 世纪 中国 已有 利用 磁石 制成 最早 指南 工具 司南 记载 公元前 世纪 史记 夏 本纪 记载 大禹治水 左 准绳 右 规矩 说明 当时 已经 简单 测绘 活动 测绘学 研究 地球 人类 地球 形状 认识 出于 不断 变化 最初 人们 认为 地球 天圆地方 直到 公元前 世纪 毕达哥拉斯 公元前 世纪 亚里士多德 提出 圆 公元前 世纪 埃拉托 斯特尼 亚历山大 进行 观测 日影 推算出 子午圈 长度 地球 半径 证实 圆 该种 方法 弧度 测量 初始 形式 世纪末 牛顿 惠更斯 力学 原理 出发 认为 地球 两极 稍 扁 椭球 形称 扁 世纪 中期 法国 科学院 南美洲 欧洲 进行 弧度 测量 证实 扁 世纪 测量 得来 数据 拉普拉斯 高斯 相继 指出 地球 并非 完美 椭球 年利 斯汀 提出 大地 水准面 概念 包围 地球 静止 海面 重合 一个 重力 等位 面 表示 地球 形状 年莫洛 坚斯基 利用 地球 重力 测量 数据 才 确定 地球 真实 形状 测绘学 成果 地图 测绘学 发展 重要 标志 便是 地图 制图 技术 提高 最早 地图 刻画 陶片 铜板 可靠性 不高 公元前 世纪 埃拉托 斯特尼 经纬线 运用 地图 公元前 西汉 初期 便 地形图 驻军 图为 目前 发现 中国 最早 地图 公元 世纪 托勒密 地理学 指南 中便 阐述 编制 地图 方法 提出 地图投影 问题 其后 西晋 裴秀 创立 制图 六体 使 地图 可靠性 得到 提升 第二次世界大战 以后 计算机 制图 技术 迅速 发展 计算机辅助 制图 发展 多位 一体 地理信息系统 测绘学 依仗 工具 测绘 仪器 测绘学 发展 离不开 测绘 工具 革新 早期 测绘 使用 简单 绳尺 矩尺 世纪 望远镜 发明 测绘 工具 变革 威理 博斯涅 尔发明 三角测量 法 开创 角度 测量 西森 研制 出测 角用 经纬仪 地理 发现 许多 国家 研究 出 海上 测定 经纬度 仪器 定位 船只 世纪 年代 洛斯 达 首创 摄影 测量法 世纪 以后 飞机 发明 出现 航空摄影 测绘 地图 方法 人造卫星 升空 卫星 定位 技术 遥感技术 得以 广泛应用 地理信息系统 技术 合称 技术\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.readline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
